---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "batchsh_collection Resource - terraform-provider-batchsh"
subcategory: ""
description: |-
  Message Collections
---

# batchsh_collection (Resource)

Message Collections



<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `datalake_id` - (String) - Batch Datalake ID
- `name` - (String) - Name
- `schema_id` - (String) - Batch Schema ID

### Optional

- `notes` - (String) - Customer Notes
- `envelope_root_message` - (String) - Protobuf message name of the root message
- `envelope_type` - (`deep` or `shallow`) - Protobuf envelope type: deep or shallow (Default: `deep`)
- `payload_field_id` - (Number) - Shallow envelope's protobuf field ID
- `payload_root_message` - (String) - Protobuf message name of the shallow envelope payload

## Attributes Reference

In addition to all arguments above, the following attributes are exported:

- `id` - (String) - Collection ID
- `archived` - (Boolean) - Whether or not the collection is archived
- `paused` - (Boolean) - Is the collection paused
- `token` - (String) - Ingestion token
- `inserted_at` - (String) - Date the collection was created
- `updated_at` - (String) - Date the collection was last updated

## Example Usage

---

### Create a JSON collection

```hcl
resource "batchsh_collection" "test" {
  name          = "My TF Managed Collection"
  notes         = "Any notes you wish to keep about this collection"
  envelope_type = "deep"
  schema_id     = "8fd90fe5-878c-4f50-abea-0d49664b19f1"
  datalake_id   = "9df46125-6479-4a29-9e15-ab2f9f93387a"
}
```

### Create a collection using data sources

You can use filters on data sources to pull the Schema and Datalake IDs based on their name

```hcl
variable "datalake" {
  type = string

  // Change to your schema name or use default JSON
  // Wildcards "*" are accepted
  default = "Default DataLake"
}

variable "schema" {
  type = string

  // Change to your schema name or use default JSON
  // Wildcards "*" are accepted
  default = "Generic JSON"
}

data "batchsh_datalake" "collection_lake" {
  filter {
    name   = "name"
    values = [var.datalake]
  }
}

data "batchsh_schema" "collection_schema" {
  filter {
    name   = "name"
    values = [var.schema]
  }
}

resource "batchsh_collection" "test" {
  name          = "My TF Managed Collection"
  notes         = "Any notes you wish to keep about this collection"
  envelope_type = "deep"
  schema_id     = data.batchsh_schema.collection_schema.id
  datalake_id   = data.batchsh_datalake.collection_lake.id
}
```

### Create a collection for protobuf encoded messages

To create a protobuf collection, you will need to specify the `envelope_root_message` and `envelope_type` fields.

Deep envelope example:
```hcl
resource "batchsh_collection" "test" {
  name                  = "My TF Managed Collection"
  notes                 = "This uses proto schema v1.0"
  envelope_type         = "deep"
  schema_id             = data.batchsh_schema.collection_schema.id
  datalake_id           = data.batchsh_datalake.collection_lake.id
  envelope_root_message = "events.Message"
}
```

If the envelope type is `shallow`, you will also need to specify the `payload_field_id` and 
`payload_root_message` fields. The `payload_field_id` is the protobuf field number in your envelope
message that contains encoded contents of a `payload_root_message` type message.


```hcl
resource "batchsh_collection" "test" {
  name                  = "My TF Managed Collection"
  notes                 = "This uses proto schema v1.0"
  envelope_type         = "deep"
  schema_id             = data.batchsh_schema.collection_schema.id
  datalake_id           = data.batchsh_datalake.collection_lake.id
  envelope_root_message = "events.Message"
  payload_root_message  = "events.Payload"
  payload_field_id      = 2
}
```


## Import

You can import existing collections, created via the Batch website, using the collection ID

```bash
$ terraform import batchsh_collection.my_collection 8fd90fe5-878c-4f50-abea-0d49664b19f1
```